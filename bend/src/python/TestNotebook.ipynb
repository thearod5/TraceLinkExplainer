{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = pathlib.Path().absolute()\n",
    "PATH_TO_DATA = os.path.join(CURRENT_PATH, \"..\", \"..\", \"..\", \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKED_MATRICES = {\n",
    "    \"Requirements\": [(\"Level_1_to_Level_2.csv\", 0), (\"Level_1_to_Level_3.csv\", 0)],\n",
    "    \"Designs\": [(\"Level_1_to_Level_2.csv\", 1), (\"Level_2_to_Level_3.csv\", 0)],\n",
    "    \"Classes\": [(\"Level_1_to_Level_3.csv\", 1), (\"Level_2_to_Level_3.csv\", 1)]\n",
    "}\n",
    "SOURCE_MATRICES = {\n",
    "    \"Level_1_to_Level_2.csv\": {\n",
    "        0: \"Requirements\",\n",
    "        1: \"Designs\"\n",
    "    },\n",
    "    \"Level_1_to_Level_3.csv\": {\n",
    "        0: \"Requirements\",\n",
    "        1: \"Classes\"\n",
    "    },\n",
    "    \"Level_2_to_Level_3.csv\": {\n",
    "        0: \"Designs\",\n",
    "        1: \"Classes\"\n",
    "    }\n",
    "}\n",
    "\n",
    "ARTIFACT_NOT_FOUND = \"ARTIFACT_NOT_FOUND\"\n",
    "\n",
    "\n",
    "def get_dataset_path(dataset_name: str):\n",
    "    dataset_query = list(\n",
    "        filter(lambda f: f[0] != \".\", os.listdir(PATH_TO_DATA)))\n",
    "    assert dataset_name in dataset_query, 'Could not find dataset: %s' % dataset_name\n",
    "    return os.path.join(PATH_TO_DATA, dataset_name)\n",
    "\n",
    "\n",
    "def get_path_to_artifacts(dataset: str, artifact_type: str, hasExtension=False):\n",
    "    path_to_dataset = get_dataset_path(dataset)\n",
    "    artifact_type_query = list(\n",
    "        filter(lambda f: f[0] != \".\", os.listdir(path_to_dataset)))\n",
    "    artifact_type_file_name = artifact_type + \\\n",
    "        \"\" if hasExtension else artifact_type + \".json\"\n",
    "    assert artifact_type_file_name in artifact_type_query, \"Could not find artifact set: %s\" % artifact_type\n",
    "    return os.path.join(path_to_dataset, artifact_type_file_name)\n",
    "\n",
    "\n",
    "def get_path_to_trace_matrices(dataset: str):\n",
    "    path_to_dataset = get_dataset_path(dataset)\n",
    "    assert \"TraceMatrices\" in os.listdir(\n",
    "        path_to_dataset), \"Cannot find trace matrices in %s\" % dataset\n",
    "    return os.path.join(path_to_dataset, \"TraceMatrices\")\n",
    "\n",
    "\n",
    "def get_traced_artifacts(dataset: str, source_artifact_type: str, source_artifact_id: str):\n",
    "    global_traced_artifacts = []\n",
    "    path_to_trace_matrices = get_path_to_trace_matrices(dataset)\n",
    "    linked_trace_matrices = LINKED_MATRICES[source_artifact_type]\n",
    "\n",
    "    for trace_matrix_name, target_axis in linked_trace_matrices:\n",
    "        # 1. Load paths\n",
    "        source_axis = 1 - target_axis  # 1 - 0 = 1 | 1 - 1 = 0 (flips bit)\n",
    "        source_artifact_type = SOURCE_MATRICES[trace_matrix_name][source_axis]\n",
    "        path_to_linked_matrix = os.path.join(\n",
    "            path_to_trace_matrices, trace_matrix_name)\n",
    "\n",
    "        # 2. Find Traced Artifacts\n",
    "        trace_matrices = pd.read_csv(path_to_linked_matrix).set_index(\"id\")\n",
    "        artifacts_in_type = get_dataset_artifacts_for_type(\n",
    "            dataset, source_artifact_type)[\"artifacts\"]\n",
    "\n",
    "        # 3. Get traced artifacts ids\n",
    "        search_id_list = trace_matrices.index if target_axis == 0 else trace_matrices.columns\n",
    "        if source_artifact_id not in search_id_list:\n",
    "            return create_error(ARTIFACT_NOT_FOUND, \"Source artifact not found: %s\" % source_artifact_id)\n",
    "        query = trace_matrices.loc[source_artifact_id] if target_axis == 0 else trace_matrices[source_artifact_id]\n",
    "        traced_artifact_ids = query[query == 1].index\n",
    "\n",
    "        # 4. Load Traced Artifacts\n",
    "        for traced_artifact_id in traced_artifact_ids:\n",
    "            traced_artifacts = list(filter(\n",
    "                lambda artifact: artifact[\"id\"] == traced_artifact_id, artifacts_in_type))\n",
    "            global_traced_artifacts = global_traced_artifacts + traced_artifacts\n",
    "\n",
    "    return global_traced_artifacts\n",
    "\n",
    "\n",
    "def create_error(id, message):\n",
    "    return {\n",
    "        \"error\": id,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "\n",
    "def get_dataset_artifacts_for_type(dataset: str, artifact_type: str, hasExtension=False):\n",
    "    path_to_artifacts = get_path_to_artifacts(\n",
    "        dataset, artifact_type, hasExtension=hasExtension)\n",
    "    data = None\n",
    "    with open(path_to_artifacts) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_all_artifacts_for_dataset(dataset: str):\n",
    "    path_to_dataset = get_dataset_path(dataset)\n",
    "    artifact_types = list(\n",
    "        filter(lambda f: f[0] != \".\" and \".json\" in f, os.listdir(path_to_dataset)))\n",
    "    return list(map(lambda a_type: get_dataset_artifacts_for_type(dataset, a_type, True), artifact_types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0, 1, 2][:None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
